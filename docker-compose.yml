version: "3.7"

services:
#  bitwarden:
#    container_name: bitwarden
#    image: vaultwarden/server
#    restart: unless-stopped
#    user: ${PUID}:1000
#    ports:
#      - ${PORT_BITWARDEN_HTTP}:80
#      - ${PORT_BITWARDEN_HTTPS}:443
#    depends_on:
#      - 'caddy'
#    volumes:
#      - ${CONFIGDIR}/bitwarden:/data
#      - ${LOGDIR}/bitwarden:/var/log/vaultwarden
#    environment:
#      TZ: ${TZ}
#      # LOG_FILE: ${LOGDIR}/bitwarden.log
#      LOG_LEVEL: ${LOG_LEVEL:-warn}
#      EXTENDED-LOGGING: 'true'
#      WEBSOCKET_ENABLED: 'true' # Required to use websockets
#      SIGNUPS_ALLOWED: 'false'   # set to false to disable signups
#      INVITATIONS_ALLOWED: 'false'
#      SHOW_PASSWORD_HINT: 'false' # set to false to improve security (slightly)
#    
#    logging:
#      driver: "json-file"
#      options:
#        max-size: "5m"
#        max-file: "10"

  crowdsec:
    container_name: crowdsec
    image: crowdsecurity/crowdsec:v1.3.0
    depends_on:
      - caddy
    restart: always
    ports:
      - ${PORT_CROWDSEC_REST}:8080 # exposes a REST API for bouncers, cscli and communication between crowdsec agent and local api
      - ${PORT_CROWDSEC_METRICS}:6060 #exposes prometheus metrics on /metrics and pprof debugging metrics on /debug
    environment:
      TZ: ${TZ}
      GID: ${PGID}
      COLLECTIONS: "crowdsecurity/caddy crowdsecurity/caddy-logs crowdsecurity/sshd"

    networks:
      - caddy-net

    volumes:
      #- ${STATICONFIGDIR}/crowdsec/config.yaml:/etc/crowdsec/config.yaml
      - ${STATICONFIGDIR}/crowdsec/acquis.yaml:/etc/crowdsec/acquis.yaml

      - crowdsec-config:/etc/crowdsec/
      - crowdsec-db:/var/lib/crowdsec/data/
    #  - ${CONFIGDIR}/crowdsec:/etc/crowdsec/ # This is my preferred way to get things working, but currently doesn't work

      ## Log Files
      - ${LOGDIR}/caddy:/var/log/caddy:ro ## check https://hub.crowdsec.net/author/crowdsecurity/configurations/caddy-logs
      - /var/log/auth.log:/logs/auth.log:ro
      - /var/log/syslog.log:/logs/syslog.log:ro
      

    healthcheck:
      test: ["CMD","cscli metrics","cscli hub list"]
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 128M
    
    #networks:
    # crowdsec_test:
    #   ipv4_address: 172.20.0.4
         
  caddy:
    container_name: caddy
    build:
      context: ${DOCKERDIR}
      dockerfile: caddy.dockerfile #Custom build which uses duckdns
    depends_on:
      - jellyfin
      - uptime-kuma
    external_links:
      - jellyfin:jellyfin
      - uptime-kuma:uptime-kuma
    restart: unless-stopped
    ports:
        - ${PORT_CADDY_HTTP}:80
        - ${PORT_CADDY_HTTPS}:443
    networks:
        - web
        - caddy-net
        - htpc-net
    volumes:
      - ${STATICONFIGDIR}/caddy/Caddyfile:/etc/caddy/Caddyfile # Required. Needs to be an extension-less file NOT a directory
      - ${CONFIGDIR}:/data # Optional, house for certs. Caddy adds its own /caddy/ directory
      - ${CONFIGDIR}:/config # Optional, JSON Config files. Caddy adds its own /caddy/ directory
      - ${LOGDIR}/caddy:/server/logs/caddy ## check for /access.log
    environment:
      LOG_FILE: ${LOGDIR}/caddy/access.log
      DOMAIN: ${DOMAIN}
      EMAIL: ${EMAIL_ADMIN}
      DUCKDNS_API_TOKEN: ${DUCKDNS_TOKEN}
    healthcheck:
      test: ["CMD", "caddy", "version"]
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 64M
  
#  duckdns:
#    container_name: duckdns
#    image: ghcr.io/linuxserver/duckdns
#    environment:
#      PUID: ${PUID}
#      PGID: ${PGID}
#      TZ: ${TZ}
#      SUBDOMAINS: ${DUCKDNS_SUBDOMAINLIST}
#      TOKEN: ${DUCKDNS_TOKEN}
#      LOG_FILE: ${LOGDIR}/duckdns.log #optional
#    volumes:
#      - ${CONFIGDIR}/duckdns:/config #optional
#    restart: unless-stopped
  
  jellyfin:
    container_name: jellyfin
    image: jellyfin/jellyfin
    user: ${PUID}:${PGID}
    #network_mode: "host" #This option will tell the container to use the same network as the computer that it is running on. This means that if you have this running on your windows machine, you will be able to access jellyfin by using http://localhost:8096 instead of a different IP
    environment:
      PUID: ${PUID}
      PGID: ${PGID}
      TZ: ${TZ}
      JELLYFIN_PublishedServerUrl: ${JELLYFIN_URL} #optional. The Server URL to publish in udp Auto Discovery response.
    volumes:
      - ${CONFIGDIR}/jellyfin:/config
      - ${CACHEDIR}/jellyfin:/cache
      - ${MEDIADIR}:/media:ro
      - ${SSL_CERT_FILE}:/srv/certs/caddy.crt:ro ### Read-only cert
    ports:
      - ${PORT_HTPC_HTTP}:8096 #HTTP webUI
      - ${PORT_HTPC_HTTPS}:8920 #HTTPS webUI
      - ${PORT_HTPC_LOCAL}:7359/udp #optional. Allows clients to discover Jellyfin on the local network.
      - ${PORT_HTPC_DLNA}:1900/udp #optional. Service discovery used by DNLA and clients.
    restart: unless-stopped
    #devices:
    #  - /dev/dri:/dev/dri #optional Only needed if you want to use your Intel GPU for hardware accelerated video encoding (vaapi).
    networks:
      - htpc-net
      - caddy-net #suggested by https://geek-cookbook.funkypenguin.co.nz/recipes/jellyfin/
    #deploy:
    #  resources:
    #    limits:
    #      cpus: '2'
    #      memory: 1024M

  heimdall:
    image: ghcr.io/linuxserver/heimdall
    container_name: heimdall
    environment:
      PUID: ${PUID}
      PGID: ${PGID}
      TZ: ${TZ}
    volumes:
      - ${CONFIGDIR}/heimdall:/config
    ports:
      - ${PORT_DASH_HTTP}:80
      - ${PORT_DASH_HTTPS}:443
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 128M

#  portainer:
#    container_name: portainer
#    image: portainer/portainer-ce
#    restart: always
#    command: -H unix:///var/run/docker.sock
#    ports:
#      - ${PORT_PORTAINER_AGENT}:8000
#      - ${PORT_PORTAINER_UI}:9000
#    volumes:
#      - /var/run/docker.sock:/var/run/docker.sock
#      - ${CONFIGDIR}/portainer/data:/data
#      - ${CONFIGDIR}/shared:/shared
#    environment:
#      TZ: ${TZ}

  uptime-kuma:
    container_name: uptime_kuma
    image: louislam/uptime-kuma
    restart: always
    ports:
      - ${PORT_UPKUMA}:3001
    networks:
      - caddy-net
    volumes:
      - ${CONFIGDIR}/uptime-kuma:/app/data
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 128M
      
volumes:
  crowdsec-config:
  crowdsec-db:

networks:
  web:
    name: web
    external: true
  htpc-net:
    name: htpc-net
  caddy-net:
    name: caddy-net
#  crowdsec_test:
#    ipam:
#      driver: default
#      config:
#        - subnet: 172.20.0.0/24